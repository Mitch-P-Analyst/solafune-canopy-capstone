{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca8d39fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics.data.converter import convert_coco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1365d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Annotations /Users/mitchellpalmer/Projects/solafune-canopy-capstone-clean/data/train.json: 100%|██████████| 150/150 [00:00<00:00, 281.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COCO data converted successfully.\n",
      "Results saved to /Users/mitchellpalmer/Projects/solafune-canopy-capstone-clean/yolo_annos2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "convert_coco (\n",
    "    labels_dir='data',\n",
    "    save_dir='yolo_annos',\n",
    "    use_keypoints= False,\n",
    "    use_segments=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67a9f0a",
   "metadata": {},
   "source": [
    "2. Automatic dataset split with Python\n",
    "\n",
    "If all your images are currently in one folder (with labels alongside), you can split them like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "341a23b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random, shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# Paths\n",
    "IMG_DIR = Path(\"model-data/images copy/train\")\n",
    "LBL_DIR = Path(\"model-data/labels copy/train\")\n",
    "\n",
    "OUT_DIR = Path(\"data\")\n",
    "splits = {\"train\": 0.7, \"val\": 0.3, \"test\": 0.0}  # 70/30/00 split\n",
    "\n",
    "# Collect all images\n",
    "images = list(IMG_DIR.glob(\"*.jpg\")) + list(IMG_DIR.glob(\"*.png\")) + list(IMG_DIR.glob(\"*.tif\")) # glob is from package Path\n",
    "random.shuffle(images)\n",
    "\n",
    "# Split indices\n",
    "n = len(images)\n",
    "train_end = int(splits[\"train\"] * n)\n",
    "val_end = train_end + int(splits[\"val\"] * n)\n",
    "\n",
    "datasets = {\n",
    "    \"train\": images[:train_end],\n",
    "    \"val\": images[train_end:val_end],\n",
    "    \"test\": images[val_end:],\n",
    "}\n",
    "\n",
    "# Copy files into YOLO structure\n",
    "for split, files in datasets.items():\n",
    "    (OUT_DIR / \"images\" / split).mkdir(parents=True, exist_ok=True)\n",
    "    (OUT_DIR / \"labels\" / split).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for img in files:\n",
    "        label = LBL_DIR / (img.stem + \".txt\")\n",
    "        shutil.copy(img, OUT_DIR / \"images\" / split / img.name)\n",
    "        if label.exists():\n",
    "            shutil.copy(label, OUT_DIR / \"labels\" / split / label.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa69242e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.backends.mps.is_available())\n",
    "print(torch.backends.mps.is_built())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "843a20d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.mps.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec42fa24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Create a new YOLO model from scratch\n",
    "model = YOLO(\"yolo11n.yaml\")\n",
    "\n",
    "# Load a pretrained YOLO model (recommended for training)\n",
    "model = YOLO(\"yolo11n.pt\")\n",
    "\n",
    "# Train the model using the 'coco8.yaml' dataset for 3 epochs\n",
    "results = model.train(data=\"coco8.yaml\", epochs=3)\n",
    "\n",
    "# Evaluate the model's performance on the validation set\n",
    "results = model.val()\n",
    "\n",
    "# Perform object detection on an image using the model\n",
    "results = model(\"https://ultralytics.com/images/bus.jpg\")\n",
    "\n",
    "# Export the model to ONNX format\n",
    "success = model.export(format=\"onnx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLenv3.10 (PyTorch)",
   "language": "python",
   "name": "mlenv3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
