{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "O-uFJyQRsTvr",
      "metadata": {
        "id": "O-uFJyQRsTvr"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XwHQNY67uM59",
      "metadata": {
        "id": "XwHQNY67uM59"
      },
      "source": [
        "\n",
        "## JSON Conversion\n",
        "### COCO Format to YOLO Machine Learning Format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca8d39fb",
      "metadata": {
        "id": "ca8d39fb"
      },
      "outputs": [],
      "source": [
        "from ultralytics.data.converter import convert_coco"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a1365d4c",
      "metadata": {
        "id": "a1365d4c",
        "outputId": "5e75d582-0692-496c-b6ae-69db3bd67318"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Annotations /Users/mitchellpalmer/Projects/solafune-canopy-capstone-clean/data/train.json: 100%|██████████| 150/150 [00:00<00:00, 281.76it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "COCO data converted successfully.\n",
            "Results saved to /Users/mitchellpalmer/Projects/solafune-canopy-capstone-clean/yolo_annos2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "convert_coco (\n",
        "    labels_dir='data', # Target is a JSON file in 'Data' directory\n",
        "    save_dir='yolo_annos',\n",
        "    use_keypoints= False,\n",
        "    use_segments=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "I1sXKcRMs4sY",
      "metadata": {
        "id": "I1sXKcRMs4sY"
      },
      "source": [
        "## Data Split | Train / Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c67a9f0a",
      "metadata": {
        "id": "c67a9f0a"
      },
      "source": [
        "- Automatic dataset split with Python. Using transferable code for designated directory paths\n",
        "\n",
        "- Training Data split 70:30 between **Training** and **Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "341a23b1",
      "metadata": {
        "id": "341a23b1"
      },
      "outputs": [],
      "source": [
        "import os, random, shutil\n",
        "from pathlib import Path\n",
        "\n",
        "# Paths\n",
        "IMG_DIR = Path(\"model-data/images copy/train\")\n",
        "LBL_DIR = Path(\"model-data/labels copy/train\")\n",
        "\n",
        "OUT_DIR = Path(\"data\")\n",
        "splits = {\"train\": 0.7, \"val\": 0.3, \"test\": 0.0}  # 70/30/00 split\n",
        "\n",
        "# Collect all images\n",
        "images = list(IMG_DIR.glob(\"*.jpg\")) + list(IMG_DIR.glob(\"*.png\")) + list(IMG_DIR.glob(\"*.tif\")) # glob is from package Path\n",
        "random.shuffle(images)\n",
        "\n",
        "# Split indices\n",
        "n = len(images)\n",
        "train_end = int(splits[\"train\"] * n)\n",
        "val_end = train_end + int(splits[\"val\"] * n)\n",
        "\n",
        "datasets = {\n",
        "    \"train\": images[:train_end],\n",
        "    \"val\": images[train_end:val_end],\n",
        "    \"test\": images[val_end:],\n",
        "}\n",
        "\n",
        "# Copy files into YOLO structure\n",
        "for split, files in datasets.items():\n",
        "    (OUT_DIR / \"images\" / split).mkdir(parents=True, exist_ok=True)\n",
        "    (OUT_DIR / \"labels\" / split).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    for img in files:\n",
        "        label = LBL_DIR / (img.stem + \".txt\")\n",
        "        shutil.copy(img, OUT_DIR / \"images\" / split / img.name)\n",
        "        if label.exists():\n",
        "            shutil.copy(label, OUT_DIR / \"labels\" / split / label.name)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "WHgN8I2KtZDe",
      "metadata": {
        "id": "WHgN8I2KtZDe"
      },
      "source": [
        "## YOLO Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "G3ilyvb8udVg",
      "metadata": {
        "id": "G3ilyvb8udVg"
      },
      "outputs": [],
      "source": [
        "import ultralytics\n",
        "from ultralytics import YOLO\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# Load a pretrained model\n",
        "model = YOLO('yolo11s-seg.pt') # yolo version 11s segementation\n",
        "\n",
        "# Train the model\n",
        "results = model.train(\n",
        "                    data = 'training_configuration_tree_canopy-seg.yaml', # Data Source\n",
        "                    device='mps',        # your Apple Metal GPU\n",
        "                    epochs=100,          # number of training epochs\n",
        "                    imgsz=416,           # image size (default 640)\n",
        "                    batch=1,             # batch size\n",
        "                    seed=0,               # Faced numers NMS issues. Stating for comparisons across parameter changes/model changes\n",
        "\n",
        "                    name='training_fastNMS',\n",
        "                    conf=0.5,           # filter low-confidence preds early\n",
        "                    iou=0.5,             # merge more aggressively in NMS\n",
        "                    max_det=100,         # cap kept detections per image\n",
        "                    val=True,\n",
        "                    plots=False,           # don't draw plots every val\n",
        "                    agnostic_nms=True,     # merge across classes\n",
        "                    workers=2              # keep small on macOS/MPS\n",
        "                    # save_json=False,     # skip COCO json export during train\n",
        "                    # workers=4            # if your CPU can handle it\n",
        "                    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "843a20d3",
      "metadata": {
        "id": "843a20d3"
      },
      "outputs": [],
      "source": [
        "# Initial run on local MacOS with MPS GPU\n",
        "\n",
        "# import torch\n",
        "# torch.mps.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec42fa24",
      "metadata": {
        "id": "ec42fa24"
      },
      "outputs": [],
      "source": [
        "# ---- Example Formatting For YOLO Model Phases ----\n",
        "\n",
        "# from ultralytics import YOLO\n",
        "\n",
        "# # Create a new YOLO model from scratch\n",
        "# model = YOLO(\"yolo11n.yaml\")\n",
        "\n",
        "# # Load a pretrained YOLO model (recommended for training)\n",
        "# model = YOLO(\"yolo11n.pt\")\n",
        "\n",
        "# # Train the model using the 'coco8.yaml' dataset for 3 epochs\n",
        "# results = model.train(data=\"coco8.yaml\", epochs=3)\n",
        "\n",
        "# # Evaluate the model's performance on the validation set\n",
        "# results = model.val()\n",
        "\n",
        "# # Perform object detection on an image using the model\n",
        "# results = model(\"https://ultralytics.com/images/bus.jpg\")\n",
        "\n",
        "# # Export the model to ONNX format\n",
        "# success = model.export(format=\"onnx\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "xK3jbQjYukwm",
      "metadata": {
        "id": "xK3jbQjYukwm"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/images/test\u001b[39m\u001b[38;5;124m'\u001b[39m,show\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ],
      "source": [
        "results = model.predict('data/images/test',show=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "490146f6",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "MLenv3.10 (PyTorch)",
      "language": "python",
      "name": "mlenv3.10"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
